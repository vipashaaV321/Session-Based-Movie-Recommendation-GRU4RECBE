{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipashaaV321/Session-Based-Movie-Recommendation-GRU4RECBE/blob/main/GRU4REC_baseLine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU4Rec BaseLine Algorithm"
      ],
      "metadata": {
        "id": "YiuHUiFHjl8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrGeZ-LN55LK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4yCGOWpVm3j"
      },
      "outputs": [],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MovieLens Dataset"
      ],
      "metadata": {
        "id": "wa5BQCncYSiD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mFiXKI555LM"
      },
      "outputs": [],
      "source": [
        "movielens_data_file_url = (\n",
        "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        ")\n",
        "movielens_zipped_file = keras.utils.get_file(\n",
        "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
        ")\n",
        "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
        "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
        "\n",
        "# Only extract the data the first time the script is run.\n",
        "if not movielens_dir.exists():\n",
        "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
        "        # Extract files\n",
        "        print(\"Extracting all the files now...\")\n",
        "        zip.extractall(path=keras_datasets_path)\n",
        "        print(\"Done!\")\n",
        "\n",
        "ratings_file = movielens_dir / \"ratings.csv\"\n",
        "ratings = pd.read_csv(ratings_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ox4M2UJfgZr7",
        "outputId": "b2799f2a-069a-4b12-fd1b-c377baae4ca7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRtTYklFgKa1",
        "outputId": "19b5fbdc-d33a-4226-ea9a-3a9595fe2c05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "971/971 [==============================] - 9s 7ms/step - loss: 8.3235 - top_k_categorical_accuracy: 0.2888 - val_loss: 8.4599 - val_top_k_categorical_accuracy: 3.2208e-04\n",
            "Epoch 2/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 8.0214 - top_k_categorical_accuracy: 0.1657 - val_loss: 8.4352 - val_top_k_categorical_accuracy: 0.1520\n",
            "Epoch 3/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 7.8980 - top_k_categorical_accuracy: 0.1354 - val_loss: 8.5446 - val_top_k_categorical_accuracy: 0.2942\n",
            "Epoch 4/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 7.7498 - top_k_categorical_accuracy: 0.1425 - val_loss: 8.6022 - val_top_k_categorical_accuracy: 0.0126\n",
            "Epoch 5/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 7.5677 - top_k_categorical_accuracy: 0.0613 - val_loss: 8.7550 - val_top_k_categorical_accuracy: 0.0140\n",
            "Epoch 6/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 7.3525 - top_k_categorical_accuracy: 0.0404 - val_loss: 8.9206 - val_top_k_categorical_accuracy: 0.0661\n",
            "Epoch 7/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 7.0946 - top_k_categorical_accuracy: 0.0595 - val_loss: 9.1028 - val_top_k_categorical_accuracy: 0.0345\n",
            "Epoch 8/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 6.8034 - top_k_categorical_accuracy: 0.0423 - val_loss: 9.3186 - val_top_k_categorical_accuracy: 0.0817\n",
            "Epoch 9/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 6.4982 - top_k_categorical_accuracy: 0.0528 - val_loss: 9.5393 - val_top_k_categorical_accuracy: 0.0584\n",
            "Epoch 10/10\n",
            "971/971 [==============================] - 6s 6ms/step - loss: 6.1918 - top_k_categorical_accuracy: 0.0415 - val_loss: 9.7357 - val_top_k_categorical_accuracy: 0.0530\n",
            "539/539 [==============================] - 2s 3ms/step - loss: 9.4824 - top_k_categorical_accuracy: 0.0568\n",
            "Test Loss: 9.482385635375977\n",
            "Top-10 Categorical Accuracy: 0.056801021099090576\n",
            "1/1 [==============================] - 0s 416ms/step\n",
            "Top 5 Recommendations for User 1: [1080, 1198, 1517, 1580, 3753]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
        "\n",
        "# Load MovieLens 100k dataset\n",
        "df=ratings\n",
        "\n",
        "# Mapping user and item IDs to sequential integers\n",
        "user_mapping = {user: idx for idx, user in enumerate(df['userId'].unique())}\n",
        "item_mapping = {item: idx for idx, item in enumerate(df['movieId'].unique())}\n",
        "\n",
        "df['user_idx'] = df['userId'].map(user_mapping)\n",
        "df['item_idx'] = df['movieId'].map(item_mapping)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model parameters\n",
        "num_users = len(user_mapping)\n",
        "num_items = len(item_mapping)\n",
        "embedding_dim = 50\n",
        "hidden_units = 100\n",
        "sequence_length = 5  # You can adjust this based on your preference\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=num_items, output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(hidden_units),\n",
        "    Dense(num_items, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=[TopKCategoricalAccuracy(k=10)])\n",
        "\n",
        "# Training data preparation\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for user_id, group in train.groupby('user_idx'):\n",
        "    items = group['item_idx'].values\n",
        "    for i in range(len(items) - sequence_length):\n",
        "        X_train.append(items[i:i + sequence_length])\n",
        "        y_train.append(items[i + sequence_length])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Testing data preparation\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for user_id, group in test.groupby('user_idx'):\n",
        "    items = group['item_idx'].values\n",
        "    for i in range(len(items) - sequence_length):\n",
        "        X_test.append(items[i:i + sequence_length])\n",
        "        y_test.append(items[i + sequence_length])\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Top-10 Categorical Accuracy: {test_accuracy}')\n",
        "\n",
        "# Generate top N recommendations for a user\n",
        "def generate_recommendations(user_idx, top_n=10):\n",
        "    user_sequence = X_test[user_idx].reshape(1, -1)\n",
        "    predictions = model.predict(user_sequence)\n",
        "    top_n_indices = np.argpartition(predictions[0], -top_n)[-top_n:]\n",
        "    recommendations = [item for item, idx in item_mapping.items() if idx in top_n_indices]\n",
        "    return recommendations\n",
        "\n",
        "# Example: Generate top 5 recommendations for user with index 0\n",
        "user_idx_to_recommend = 1\n",
        "top_n_recommendations = generate_recommendations(user_idx_to_recommend, top_n=5)\n",
        "print(f'Top 5 Recommendations for User {user_idx_to_recommend}: {top_n_recommendations}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLKc-B0_gR5i",
        "outputId": "ce59e0cf-65b6-4efb-d2a3-a2957f0f175a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 13ms/step\n",
            "Top 5 Recommendations for User 1:\n",
            "Movie ID: 1015\n",
            "Movie ID: 70\n",
            "Movie ID: 61\n",
            "Movie ID: 101\n",
            "Movie ID: 98\n"
          ]
        }
      ],
      "source": [
        "# Generate top N recommendations for a user with movie names and titles\n",
        "def generate_recommendations_with_names(user_idx, top_n=10):\n",
        "    user_sequence = X_test[user_idx].reshape(1, -1)\n",
        "    predictions = model.predict(user_sequence)\n",
        "    top_n_indices = np.argpartition(predictions[0], -top_n)[-top_n:]\n",
        "\n",
        "    recommendations = [(item, item_mapping.get(item, 'Unknown')) for item in top_n_indices]\n",
        "    return recommendations\n",
        "\n",
        "# Example: Generate top 5 recommendations with movie names and titles for user with index 0\n",
        "user_idx_to_recommend = 1\n",
        "top_n_recommendations_with_names = generate_recommendations_with_names(user_idx_to_recommend, top_n=5)\n",
        "\n",
        "print(f'Top 5 Recommendations for User {user_idx_to_recommend}:')\n",
        "for item, title in top_n_recommendations_with_names:\n",
        "    print(f'Movie ID: {item}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yoEZM5KJjjw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_reciprocal_rank(ranks):\n",
        "    return np.mean(1.0 / ranks)\n",
        "\n",
        "def normalized_discounted_cumulative_gain(ranks):\n",
        "    # Ideal ranking\n",
        "    ideal_ranks = np.sort(ranks)\n",
        "    dcg = np.sum(1.0 / np.log2(ideal_ranks + 2))\n",
        "    idcg = np.sum(1.0 / np.log2(np.arange(2, len(ideal_ranks) + 2)))\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def hit_rate(ranks, threshold=10):\n",
        "    return np.mean(ranks <= threshold)\n",
        "\n",
        "# Testing data preparation for evaluation\n",
        "X_test_eval = []\n",
        "y_test_eval = []\n",
        "\n",
        "for user_id, group in test.groupby('user_idx'):\n",
        "    items = group['item_idx'].values\n",
        "    # Extract the actual ratings/preferences for the user from the last item in the sequence\n",
        "    actual_ranking = items[-1]  # Assuming the last item in the sequence is the user's preference\n",
        "    # Append the actual ranking to the ground_truth_rankings list\n",
        "    ground_truth_rankings.append(actual_ranking)\n",
        "\n",
        "    for i in range(len(items) - sequence_length):\n",
        "        X_test_eval.append(items[i:i + sequence_length])\n",
        "        y_test_eval.append(items[i + sequence_length])\n",
        "\n",
        "X_test_eval = np.array(X_test_eval)\n",
        "y_test_eval = np.array(y_test_eval)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkyQ05b6Q6mS",
        "outputId": "14044729-4dce-4378-a6c7-7e5316883527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "539/539 [==============================] - 1s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model and calculate metrics\n",
        "predictions = model.predict(X_test_eval)\n",
        "top_n_indices = np.argpartition(predictions, -10, axis=1)[:, -10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvOXgdW_Q8vU",
        "outputId": "8693c171-2ad0-4b0e-b496-7720dc96684e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 232,    0,   65, ...,   42,   34,  101],\n",
              "       [ 197,   75,  141, ...,   61,  101, 1015],\n",
              "       [  15,    7,   68, ...,  101,  322,  335],\n",
              "       ...,\n",
              "       [ 415, 1500, 1758, ..., 3300,  330,  104],\n",
              "       [2175,  224, 1470, ..., 2087, 2161, 2188],\n",
              "       [  59, 1115,  191, ..., 3574, 4870, 1564]], dtype=int64)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_n_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaG5-5P8Vm3m",
        "outputId": "f09d4be4-3275-4cb0-eb0b-76fd58f6b086"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(top_n_recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_c5bAcgW6xz",
        "outputId": "5a39babc-8e0e-48e9-d657-760a3061d261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Reciprocal Rank (MRR): 0.20541776725366478\n",
            "Hit Rate at position 1: 0.2\n",
            "Normalized Discounted Cumulative Gain (NDCG) at position 5: 0.3985488025814338\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate Mean Reciprocal Rank (MRR)\n",
        "def calculate_mrr(rankings):\n",
        "    reciprocal_ranks = [1 / (rank + 1) for rank in rankings]\n",
        "    return np.mean(reciprocal_ranks)\n",
        "\n",
        "# Function to calculate Hit Rate at a given position\n",
        "def calculate_hit_rate(rankings, position):\n",
        "    hits = [1 if rank <= position else 0 for rank in rankings]\n",
        "    return np.mean(hits)\n",
        "\n",
        "# Function to calculate Discounted Cumulative Gain (DCG) at a given position\n",
        "def calculate_dcg(rankings, position):\n",
        "    dcg = np.sum([(2 ** relevance - 1) / np.log2(rank + 2) for rank, relevance in enumerate(rankings[:position])])\n",
        "    return dcg\n",
        "\n",
        "# Function to calculate Normalized Discounted Cumulative Gain (NDCG) at a given position\n",
        "def calculate_ndcg(rankings, position):\n",
        "    ideal_rankings = sorted(rankings, reverse=True)\n",
        "    ideal_dcg = calculate_dcg(ideal_rankings, position)\n",
        "    ndcg = calculate_dcg(rankings, position) / ideal_dcg if ideal_dcg > 0 else 0\n",
        "    return ndcg\n",
        "\n",
        "\n",
        "# Extract movie IDs from recommendations\n",
        "recommended_movie_ids = [item for item, _ in top_n_recommendations_with_names]\n",
        "\n",
        "# Find the position of each recommended movie in the ground truth rankings\n",
        "rankings = [ground_truth_rankings.index(movie_id) + 1 if movie_id in ground_truth_rankings else 0 for movie_id in recommended_movie_ids]\n",
        "\n",
        "# Calculate and print metrics\n",
        "print(f'Mean Reciprocal Rank (MRR): {calculate_mrr(rankings)}')\n",
        "print(f'Hit Rate at position 1: {calculate_hit_rate(rankings, position=1)}')\n",
        "print(f'Normalized Discounted Cumulative Gain (NDCG) at position 5: {calculate_ndcg(rankings, position=5)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKRKHlgVXtWu",
        "outputId": "0c5723e2-84ee-4aea-e60b-1ad63521b493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit Rate at position 5: 0.2\n",
            "Hit Rate at position 10: 0.4\n",
            "NDCG at position 5: 0.3985488025814338\n",
            "NDCG at position 10: 0.3985488025814338\n"
          ]
        }
      ],
      "source": [
        "# Calculate Hit Rate at positions 5 and 10\n",
        "hit_rate_at_5 = calculate_hit_rate(rankings, position=5)\n",
        "hit_rate_at_10 = calculate_hit_rate(rankings, position=53)\n",
        "\n",
        "# Calculate NDCG at positions 5 and 10\n",
        "ndcg_at_5 = calculate_ndcg(rankings, position=5)\n",
        "ndcg_at_10 = calculate_ndcg(rankings, position=100)\n",
        "\n",
        "# Print the updated metrics\n",
        "print(f'Hit Rate at position 5: {hit_rate_at_5}')\n",
        "print(f'Hit Rate at position 10: {hit_rate_at_10}')\n",
        "print(f'NDCG at position 5: {ndcg_at_5}')\n",
        "print(f'NDCG at position 10: {ndcg_at_10}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXoaziSsVm3n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW9DMbkJVm3n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}